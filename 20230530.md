# QR코드 스캔 프로그램
- 바코드나 QR코드 인식을 하기 위해서는 pyzbar가 필요
- 'pip list | grep 항목' 으로 원하는 pip 항목을 볼 수 있다
- pyzbar 설치 : pip install pyzbar (https://pypi.org/project/pyzbar/) 
- 'pip list | grep pyzbar'을 통해 제대로 설치되었는지 확인
- sudo apt-get install libzbar0
- QR코드 만들기 : (https://qr.naver.com/code/createForm.naver)

### QR코드 확인
```python
import cv2
import pyzbar.pyzbar as pyzbar # pyzbar 가져오기
import matplotlib.pyplot as plt

img = cv2.imread('QR.jpg') # 이미지를 불러오기
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # 3채널을 1채널로 변환


# plt.imshow(img) # 이미지를 확인해보기
# plt.imshow(gray, cmap='gray')
# matplot 실행하기
# plt.show()

decoded = pyzbar.decode(gray) # pyzbar로 decode를 해주기

# decode된 정보 확인하기
# print(decoded)

for d in decoded:
    print(d.type) # 데이터 타입을 알려준다
    print(d.data) # d.(주소 데이터)의 형태를 지니고 있다 
    print(d.data.decode('utf-8')) # 주소창만 표기
    
    # rectangle함수를 사용해서 QR코드 외곽선 만들기 
    cv2.rectangle(gray, (d.rect[0],d.rect[1]), (d.rect[0]+d.rect[2], d.rect[1]+d.rect[3]),(0, 0, 255), 10)

plt.imshow(gray, cmap='gray')
plt.show()

```
![image](https://github.com/zzeonii/OpenCV_study/assets/129237950/82bc929c-af92-477b-a880-d6434805c495)

### 웹캠으로 QR코드 인식
```python
import cv2
# pyzbar 가져오기
import pyzbar.pyzbar as pyzbar

cap = cv2.VideoCapture(0)

i = 0
while(cap.isOpened()):
    ret, img = cap.read()

    if not ret:
        continue

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    decoded = pyzbar.decode(gray)
    
    for d in decoded:
        x, y, w, h = d.rect

        barcode_data = d.data.decode("utf-8")
        barcode_type = d.type

        cv2.rectangle(img, (x,y), (x+w, y+h), (0,0,255), 2)

        text = '%s (%s)' % (barcode_data, barcode_type)
        cv2.putText(img, text, (x,y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,255), 2, cv2.LINE_AA)

    cv2.imshow('img', img)

    key = cv2.waitKey(1)
    if key == ord('q'):
        break
    elif key == ord('s'):
        i += 1
        cv2.imwrite('c_%03d.jpg' %i, img)

cap.release()
cv2.destroyAllWindows()
```
![image](https://github.com/zzeonii/OpenCV_study/assets/129237950/2e1aa4ac-5b3d-4d19-9297-3f63e1e2b332)

#### QR 코드가 감지되면 웹사이트가 자동으로 열리도록 하는 방법
```python
import cv2
import pyzbar.pyzbar as pyzbar
import webbrowser

cap = cv2.VideoCapture(0)

i = 0
while(cap.isOpened()):
    ret, img = cap.read()

    if not ret:
        continue

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    decoded = pyzbar.decode(gray)
    
    for d in decoded:
        x, y, w, h = d.rect

        barcode_data = d.data.decode("utf-8")
        barcode_type = d.type

        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 255), 2)

        text = '%s (%s)' % (barcode_data, barcode_type)
        cv2.putText(img, text, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv2.LINE_AA)

        # QR 코드가 감지되면 웹사이트를 기본 웹 브라우저에서 엽니다.
        webbrowser.open(barcode_data)

    cv2.imshow('img', img)

    key = cv2.waitKey(1)
    if key == ord('q'):
        break
    elif key == ord('s'):
        i += 1
        cv2.imwrite('c_%03d.jpg' % i, img)

cap.release()
cv2.destroyAllWindows()
```
- QR코드가 인식되는 동안 계속 브라우저가 계속 열리게 됨

#### QR 코드가 감지되면 한 번만 웹사이트를 열도록 변경
```python
import cv2
import pyzbar.pyzbar as pyzbar
import webbrowser

cap = cv2.VideoCapture(0)

i = 0
is_website_opened = False  # 웹사이트가 열렸는지 여부를 확인하는 변수
while(cap.isOpened()):
    ret, img = cap.read()

    if not ret:
        continue

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    decoded = pyzbar.decode(gray)
    
    for d in decoded:
        x, y, w, h = d.rect

        barcode_data = d.data.decode("utf-8")
        barcode_type = d.type

        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 255), 2)

        text = '%s (%s)' % (barcode_data, barcode_type)
        cv2.putText(img, text, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv2.LINE_AA)

        if not is_website_opened:
            # QR 코드가 감지되고 웹사이트가 아직 열리지 않았다면 웹사이트를 기본 웹 브라우저에서 엽니다.
            webbrowser.open(barcode_data)
            is_website_opened = True  # 웹사이트가 열렸음을 표시

    cv2.imshow('img', img)

    key = cv2.waitKey(1)
    if key == ord('q'):
        break
    elif key == ord('s'):
        i += 1
        cv2.imwrite('c_%03d.jpg' % i, img)

cap.release()
cv2.destroyAllWindows()
```

# 원근 변환(Perspective Transform)
- 이미지를 3차원으로 변환
- 원근법의 원리를 적용해 변환하는 방식
> - mtrx = cv2.getPerspectiveTransform(pts1, pts2)
>   - pts1: 변환 이전 영상의 좌표 4개, 4 x 2 배열
>   - pts2: 변환 이후 영상의 좌표 4개, 4 x 2 배열
>   - mtrx: 변환행렬 반환, 3 x 3 행렬
>   
```python
import  cv2, os
import numpy as np

# 이미지를 불러와서 변수 ori_img에 넣어준다.
img_path = 'img01.jpg'
ori_img = cv2.imread(img_path)
filename, ext = os.path.splitext(os.path.basename(img_path))

src = []
# mouse callback handler
def mouse_handler(event, x, y, flags, param):
    # 마우스의 좌측 번튼
    if event == cv2.EVENT_LBUTTONUP:
        img = ori_img.copy()
        # src에 x,y값을 저장
        src.append([x,y])
        for xx, yy in src:
            cv2.circle(img, center=(xx,yy), radius=5, color=(0,255,0), thickness=-1, lineType=cv2.LINE_AA)
        cv2.imshow('img', img)

        # perspective transform
        if len(src) == 4:
            src_np = np.array(src, dtype=np.float32)
        width = max(np.linalg.norm(src_np[0]-src_np[1]), np.linalg.norm(src_np[2]-src_np[3]))
        height = max(np.linalg.norm(src_np[0]-src_np[3]), np.linalg.norm(src_np[1]-src_np[2]))
        dst_np = np.array([[0, 0], [width, 0], [width, height], [0, height]], dtype=np.float32)

        # dst_np와 src_np의 값을 getPerspectiveTransform에 넣어준다
        M = cv2.getPerspectiveTransform(src=src_np, dst=dst_np)
        # M의 값을 warpPerspective에 넣어준다
        result = cv2.warpPerspective(ori_img, M=M, dsize=(int(width), int(height)))

        cv2.imshow('result', result)
        cv2.imwrite('./result/%s_result%s' % (filename, ext), result)

# 윈도우에 이름을 지정해주기
cv2. namedWindow('img')

# img라고 지정된 윈도우에 마우스 콜백 함수를 지정해줘서 마우스 동작이 있으면 mouse_handler가 전달이 된다.
cv2.setMouseCallback('img', mouse_handler)
# 이미지 띄우기
cv2.imshow('img', ori_img)
cv2.waitKey(0)
```
# 파노라마로 이미지 붙이기
```pyhton
import cv2
import numpy as np
import matplotlib.pyplot as plt

import os, glob

IMG_NAME = 'scottsdale'

img_list = []
for ext in ('0*.jpg', '0*.png'):
    img_list.extend(glob.glob(os.path.join('imgs', IMG_NAME, ext)))

img_list = sorted(img_list)

# print(img_list)

imgs = []

plt.figure(figsize=(20,20))

for i, img_path in enumerate(img_list):
    img = cv2.imread(img_path)
    imgs.append(img)

    plt.subplot(len(img_list) // 3+1, 3, i+1)
    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))

# plt.show
mode = cv2.STITCHER_PANORAMA

if int(cv2.__version__[0]) == 3:
    sticher = cv2.createStitcher(mode)
else:
    sticher = cv2.Stitcher_create(mode)

status, stitched = sticher.stitch(imgs)

if status == 0:
    cv2.imwrite(os.path.join('img', IMG_NAME, 'result.jpg'), stitched)

    plt.figure(figsize=(20, 20))
    plt.imshow(cv2.cvtColor(stitched, cv2.COLOR_BGR2RGB))
else:
    print('failed..%s' % status)

# plt.show()

gray = cv2.cvtColor(stitched, cv2.COLOR_BGR2GRAY)
thresh = cv2.bitwise_not(cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY)[1])
thresh = cv2.medianBlur(thresh, 5)

plt.figure(figsize=(20, 20))
plt.imshow(thresh, cmap='gray')

# plt.show()

stitched_copy = stitched.copy()
thresh_copy = thresh.copy()

while np.sum(thresh_copy) > 0:
    thresh_copy = thresh_copy[1:-1, 1:-1]
    stitched_copy = stitched_copy[1:-1, 1:-1]

cv2.imwrite(os.path.join('imgs', IMG_NAME, 'result_crop.jpg'), stitched_copy)

plt.figure(figsize=(20, 20))
plt.imshow(cv2.cvtColor(stitched_copy, cv2.COLOR_BGR2RGB))

plt.show()
```
#### fiqure1
![image](https://github.com/zzeonii/OpenCV_study/assets/129237950/02231d6d-379c-47e9-bfda-cdecbc515204)

#### fiqure2
![image](https://github.com/zzeonii/OpenCV_study/assets/129237950/671d958f-6a4e-40c6-bcbd-453b3ea56cb9)

#### fiqure3
![image](https://github.com/zzeonii/OpenCV_study/assets/129237950/7eb7a4a2-d71d-4e72-aa45-8eec6cd65bf6)

#### fiqure4
![image](https://github.com/zzeonii/OpenCV_study/assets/129237950/1a5ee338-82eb-4a75-80a3-9b42f919e98f)
