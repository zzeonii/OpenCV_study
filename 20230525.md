# 이미지 및 동영상

## 이미지 읽기
```python
import cv2

img_file = "../img/girl.jpg" # 표시할 이미지 경로            ---①
img = cv2.imread(img_file)    # 이미지를 읽어서 img 변수에 할당 ---②

if img is not None:
  cv2.imshow('IMG', img)      # 읽은 이미지를 화면에 표시      --- ③
  cv2.waitKey()               # 키가 입력될 때 까지 대기      --- ④
  cv2.destroyAllWindows()     # 창 모두 닫기            --- ⑤
else:
    print('No image file.')
```
![image](https://github.com/zzeonii/OpenCV_study/assets/129237950/d2e7d9d4-7a95-40b2-9a8f-60068fa582e0)
 
## 이미지 흑백 변환
```python
import cv2

img_file = "../img/girl.jpg" 
img = cv2.imread(img_file, cv2.IMREAD_GRAYSCALE)    # 회색으로 읽기

if img is not None:
  cv2.imshow('IMG', img)
  cv2.waitKey()
  cv2.destroyAllWindows()
else:
    print('No image file.')
```
- cv2.imread(path, flag)
  - path : 이미지 파일 경로
  - flag : 이미지를 어떻게 읽을지 방식 설정
    - cv2.IMREAD_COLOR(기본값): 색깔 이미지로 불러오기, 이때 투명도(alpha값)는 무시
    - cv2.IMREAD_GRAYSCALE: 이미지를 흑백톤으로 불러온다
    - cv2.IMREAD_UNCHANGED: 투명도(alpha값)를 포함해 이미지를 그대로 불러온다

![image](https://github.com/zzeonii/OpenCV_study/assets/129237950/02242e8c-ec3f-43a7-a26e-5dfd61ecefd2)

## 이미지 저장
```python
import cv2

img_file = '../img/girl.jpg'
save_file = '../img/girl_gray.jpg'

img = cv2.imread(img_file, cv2.IMREAD_GRAYSCALE)
cv2.imshow(img_file, img)
cv2.imwrite(save_file, img) #파일로 저장, 포맷은 확장에 따름
cv2.waitKey()
cv2.destroyAllWindows()
```
- cv2.imwrite()함수를 호출하면 img 변수에 담긴 사진 파일을 자신의 PC에 저장할 수 있다
- 상기 코드를 실행하면 img 디렉토리에 girl_gray.jpg라는 회색 사진이 생성

## 동영상 파일 읽기
### v1
```python
import cv2

video_file = "../img/big_buck.avi" # 동영상 파일 경로

cap = cv2.VideoCapture(video_file) # 동영상 캡쳐 객체 생성  ---①
if cap.isOpened():                 # 캡쳐 객체 초기화 확인
    while True:
        ret, img = cap.read()      # 다음 프레임 읽기      --- ②
        if ret:                     # 프레임 읽기 정상
            cv2.imshow(video_file, img) # 화면에 표시  --- ③
            cv2.waitKey(25)            # 25ms 지연(40fps로 가정)   --- ④
        else:                       # 다음 프레임 읽을 수 없음
            break                   # 재생 완료
else:
    print("can't open video.")      # 캡쳐 객체 초기화 실패
cap.release()                       # 캡쳐 자원 반납
cv2.destroyAllWindows()
```
### v2_프레임 수 구하기
```python
import cv2

video_file = "../img/big_buck.avi" # 동영상 파일 경로

cap = cv2.VideoCapture(video_file) # 동영상 캡쳐 객체 생성
if cap.isOpened():                 # 캡쳐 객체 초기화 확인
    fps = cap.get(cv2.CAP_PROP_FPS) # 프레임 수 구하기
    delay = int(1000/fps)
    print("FPS: %f, Delay: %dms" %(fps, delay))

    while True:
        ret, img = cap.read()      # 다음 프레임 읽기
        if ret:                     # 프레임 읽기 정상
            cv2.imshow(video_file, img) # 화면에 표시
            cv2.waitKey(delay)            # fps에 맞게 시간 지연
        else:
            break                   # 다음 프레임 읽을 수 없슴, 재생 완료
else:
    print("can't open video.")      # 캡쳐 객체 초기화 실패
cap.release()                       # 캡쳐 자원 반납
cv2.destroyAllWindows()
```
![image](https://github.com/zzeonii/OpenCV_study/assets/129237950/090480af-b59d-4c30-a4f1-7ed35665d29f)

# 카메라(웹캠)

## 카메라(웹캠) 프레임 읽기
```python
import cv2

cap = cv2.VideoCapture(0)               # 0번 카메라 장치 연결 ---①
if cap.isOpened():                      # 캡쳐 객체 연결 확인
    while True:
        ret, img = cap.read()           # 다음 프레임 읽기
        if ret:
            cv2.imshow('camera', img)   # 다음 프레임 이미지 표시
            if cv2.waitKey(1) != -1:    # 1ms 동안 키 입력 대기 ---②
                break                   # 아무 키라도 입력이 있으면 중지
        else:
            print('no frame')
            break
else:
    print("can't open camera.")
cap.release()                           # 자원 반납
cv2.destroyAllWindows()
```
![image](https://github.com/zzeonii/OpenCV_study/assets/129237950/e7595b1d-d9c6-471f-a78e-431228eea750)

## 웹캠으로 사진 찍기
```python
import cv2

cap = cv2.VideoCapture(0)                       # 0번 카메라 연결
if cap.isOpened() :
    while True:
        ret, frame = cap.read()                 # 카메라 프레임 읽기
        if ret:
            cv2.imshow('camera',frame)          # 프레임 화면에 표시
            if cv2.waitKey(1) != -1:            # 아무 키나 누르면
                cv2.imwrite('photo.jpg', frame) # 프레임을 'photo.jpg'에 저장
                break
        else:
            print('no frame!')
            break
else:
    print('no camera!')
cap.release()
cv2.destroyAllWindows()
```
- 코드 실행후 아무키나 누르면 그 순간의 프레임이 캡쳐되어 저장

## 웹캠으로 녹화
```python
import cv2

cap = cv2.VideoCapture(0)    # 0번 카메라 연결
if cap.isOpened:
    file_path = './record.avi'    # 저장할 파일 경로 이름 ---①
    fps = 30.0                     # FPS, 초당 프레임 수
    fourcc = cv2.VideoWriter_fourcc(*'DIVX') # 인코딩 포맷 문자
    width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)
    height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)
    size = (int(width), int(height))                        # 프레임 크기
    out = cv2.VideoWriter(file_path, fourcc, fps, size) # VideoWriter 객체 생성
    while True:
        ret, frame = cap.read()
        if ret:
            cv2.imshow('camera-recording',frame)
            out.write(frame)                        # 파일 저장
            if cv2.waitKey(int(1000/fps)) != -1: 
                break
        else:
            print("no frame!")
            break
    out.release()                                   # 파일 닫기
else:
    print("can't open camera!")
cap.release()
cv2.destroyAllWindows()
```
- cv2.VideoWriter(file_path, fourcc, fps, (width, height))
  - file_path : 동영상 파일 경로
  - fourcc : 동영상 인코딩 형식(codec 정보)
  - fps : 초당 저장될 프레임 수
  - size : (width, height) 프레임의 너비와 높이
- cap.get() : 동영상이나 카메라의 속성을 확인하는 함수
  - cap.get(cv2.CAP_PROP_FRAME_WIDTH) : cap 객체의 프레임 너비를 반환
  - cap.get(cv2.CAP_PROP_FRAME_HEIGHT) : cap 객체의 프레임 높이를 반환


# teachable machine
![image](https://github.com/zzeonii/OpenCV_study/assets/129237950/ba865f07-3fd2-4b58-9d6e-f65e0e387d67)

# 객체 추적(Object Tracking)
- 동영상에서 지속적으로 움직이는 객체를 찾는 방법

# 배경 제거(Background Subtraction)
- 객체를 명확히 파악하기 위한 방법
- 객체를 포함하는 영상에서 객체가 없는 배경 영상을 빼는 방법
- 배경을 모두 제거해 객체만 남기는 방법

![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FnylTp%2FbtqHXDwgRhr%2FdNooQVMOTzkBk2t3zJrcI0%2Fimg.png)
### v1
```python
import numpy as np, cv2

cap = cv2.VideoCapture('../img/walking.avi')
fps = cap.get(cv2.CAP_PROP_FPS) # 프레임 수 구하기
delay = int(1000/fps)
# 배경 제거 객체 생성 --- ①
fgbg = cv2.bgsegm.createBackgroundSubtractorMOG()
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    # 배경 제거 마스크 계산 --- ②
    fgmask = fgbg.apply(frame)
    cv2.imshow('frame',frame)
    cv2.imshow('bgsub',fgmask)
    if cv2.waitKey(1) & 0xff == 27:
        break
cap.release()
cv2.destroyAllWindows()
```
- cv2.bgsegm.createBackgroundSubtractorMOG(history, nmixtures, backgroundRatio, noiseSigma)
  - history=200: 히스토리 길이
  - nmixtures=5: 가우시안 믹스처의 개수
  - backgroundRatio=0.7: 배경 비율
  - noiseSigma=0: 노이즈 강도 (0=자동)
- foregroundmask = backgroundsubtractor.apply(img, foregroundmask, learningRate)
  - img: 입력 영상
  - foregroundmask: 전경 마스크
  - learningRate=-1: 배경 훈련 속도(0~1, -1: 자동)
- backgroundImage = backgroundsubtractor.getBackgroundImage(backgroundImage)
  - backgroundImage: 훈련용 배경 이미지
![image](https://github.com/zzeonii/OpenCV_study/assets/129237950/99624447-3b41-4f08-b0f6-b56e53d7a356)

### v2
```python
import numpy as np, cv2

cap = cv2.VideoCapture('../img/walking.avi')
fps = cap.get(cv2.CAP_PROP_FPS) # 프레임 수 구하기
delay = int(1000/fps)
# 배경 제거 객체 생성 --- ①
fgbg = cv2.createBackgroundSubtractorMOG2()
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    # 배경 제거 마스크 계산 --- ②
    fgmask = fgbg.apply(frame)
    cv2.imshow('frame',frame)
    cv2.imshow('bgsub',fgmask)
    if cv2.waitKey(delay) & 0xff == 27:
        break
cap.release()
cv2.destroyAllWindows()
```
- cv2.createBackgroundSubtractorMOG2(history, varThreshold, detectShadows)
  - history=500: 히스토리 개수
  - varThreshold=16: 분산 임계 값
  - detectShadows=True: 그림자 표시
![image](https://github.com/zzeonii/OpenCV_study/assets/129237950/07375db1-9cda-4b2f-9084-c16ea8cbc523)

## 웹캠화면에서 배경 제거
```python
import cv2

cap = cv2.VideoCapture(1)               # 0번 카메라 장치 연결 ---①
fps = cap.get(cv2.CAP_PROP_FPS) # 프레임 수 구하기
delay = int(1000/fps)

fgbg = cv2.bgsegm.createBackgroundSubtractorMOG()
if cap.isOpened():                      # 캡쳐 객체 연결 확인
    while True:
        ret, img = cap.read()           # 다음 프레임 읽기
        if ret:
            fgmask = fgbg.apply(img)
            cv2.imshow('camera', img)   # 다음 프레임 이미지 표시
            cv2.imshow('bgsub', fgmask)
            if cv2.waitKey(1) != -1:    # 1ms 동안 키 입력 대기 ---②
                break                   # 아무 키라도 입력이 있으면 중지
        else:
            print('no frame')
            break
else:
    print("can't open camera.")

cap.release()                           # 자원 반납
cv2.destroyAllWindows()
```
![image](https://github.com/zzeonii/OpenCV_study/assets/129237950/11d260c8-b26b-47ad-ad54-2d44991154e2)

# 연속 영역 분할
## 그랩컷(Graph Cut)
- 사용자가 전경(배경이 아닌 부분)으로 분리할 부분에 사각형 표시를 해주면 전경과 배경의 색상 분포를 추정해서 </br>동일한 레이블을 가진 연결된 영역에서 전경과 배경을 분리
```python
import cv2
import numpy as np

img = cv2.imread('../img/taekwonv1.jpg')
img_draw = img.copy()
mask = np.zeros(img.shape[:2], dtype=np.uint8)  # 마스크 생성
rect = [0,0,0,0]    # 사각형 영역 좌표 초기화
mode = cv2.GC_EVAL  # 그랩컷 초기 모드
# 배경 및 전경 모델 버퍼
bgdmodel = np.zeros((1,65),np.float64)
fgdmodel = np.zeros((1,65),np.float64)

# 마우스 이벤트 처리 함수
def onMouse(event, x, y, flags, param):
    global mouse_mode, rect, mask, mode
    if event == cv2.EVENT_LBUTTONDOWN : # 왼쪽 마우스 누름
        if flags <= 1: # 아무 키도 안 눌렀으면
            mode = cv2.GC_INIT_WITH_RECT # 드래그 시작, 사각형 모드 ---①
            rect[:2] = x, y # 시작 좌표 저장
    # 마우스가 움직이고 왼쪽 버튼이 눌러진 상태
    elif event == cv2.EVENT_MOUSEMOVE and flags & cv2.EVENT_FLAG_LBUTTON :
        if mode == cv2.GC_INIT_WITH_RECT: # 드래그 진행 중 ---②
            img_temp = img.copy()
            # 드래그 사각형 화면에 표시
            cv2.rectangle(img_temp, (rect[0], rect[1]), (x, y), (0,255,0), 2)
            cv2.imshow('img', img_temp)
        elif flags > 1: # 키가 눌러진 상태
            mode = cv2.GC_INIT_WITH_MASK    # 마스크 모드 ---③
            if flags & cv2.EVENT_FLAG_CTRLKEY :# 컨트롤 키, 분명한 전경
                # 흰색 점 화면에 표시
                cv2.circle(img_draw,(x,y),3, (255,255,255),-1)
                # 마스크에 GC_FGD로 채우기      ---④
                cv2.circle(mask,(x,y),3, cv2.GC_FGD,-1)
            if flags & cv2.EVENT_FLAG_SHIFTKEY : # 쉬프트키, 분명한 배경
                # 검정색 점 화면에 표시
                cv2.circle(img_draw,(x,y),3, (0,0,0),-1)
                # 마스크에 GC_BGD로 채우기      ---⑤
                cv2.circle(mask,(x,y),3, cv2.GC_BGD,-1)
            cv2.imshow('img', img_draw) # 그려진 모습 화면에 출력
    elif event == cv2.EVENT_LBUTTONUP: # 마우스 왼쪽 버튼 뗀 상태 ---⑥
        if mode == cv2.GC_INIT_WITH_RECT : # 사각형 그리기 종료
            rect[2:] =x, y # 사각형 마지막 좌표 수집
            # 사각형 그려서 화면에 출력 ---⑦
            cv2.rectangle(img_draw, (rect[0], rect[1]), (x, y), (255,0,0), 2)
            cv2.imshow('img', img_draw)
        # 그랩컷 적용 ---⑧
        cv2.grabCut(img, mask, tuple(rect), bgdmodel, fgdmodel, 1, mode)
        img2 = img.copy()
        # 마스크에 확실한 배경, 아마도 배경으로 표시된 영역을 0으로 채우기
        img2[(mask==cv2.GC_BGD) | (mask==cv2.GC_PR_BGD)] = 0
        cv2.imshow('grabcut', img2) # 최종 결과 출력
        mode = cv2.GC_EVAL # 그랩컷 모드 리셋
# 초기 화면 출력 및 마우스 이벤트 등록
cv2.imshow('img', img)
cv2.setMouseCallback('img', onMouse)
while True:    
    if cv2.waitKey(0) & 0xFF == 27 : # esc
        break
cv2.destroyAllWindows()
```
- mask, bgdModel, fgdModel = cv2.grabCut(img, mask, rect, bgdModel, fgdModel, iterCount, mode)
  - img: 입력 이미지
  - mask: 입력 이미지와 크기가 같은 1 채널 배열, 배경과 전경을 구분하는 값을 저장 </br>(cv2.GC_BGD: 확실한 배경(0), cv2.GC_FGD: 확실한 전경(1), cv2.GC_PR_BGD: 아마도 배경(2), cv2.GC_PR_FGD: 아마도 전경(3))
  - rect: 전경이 있을 것으로 추측되는 영역의 사각형 좌표, 튜플 (x1, y1, x2, y2)
  - bgdModel, fgdModel: 함수 내에서 사용할 임시 배열 버퍼 (재사용할 경우 수정하지 말 것)
  - iterCount: 반복 횟수
  - mode(optional): 동작 방법 (cv2.GC_INIT_WITH_RECT: rect에 지정한 좌표를 기준으로 그랩컷 수행, </br>cv2.GC_INIT_WITH_MASK: mask에 지정한 값을 기준으로 그랩컷 수행, cv2.GC_EVAL: 재시도)

![image](https://github.com/zzeonii/OpenCV_study/assets/129237950/8ed6818f-e202-45f3-a9ef-a853da8a7121)

