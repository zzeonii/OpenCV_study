# 미니 콘다 설치

### 참고 자료
#### 리눅스
- https://smoothiecoding.kr/%EB%AF%B8%EB%8B%88%EC%BD%98%EB%8B%A4-wsl2-vsc-%ED%8C%8C%EC%9D%B4%EC%8D%AC/
- https://webnautes.tistory.com/1499
#### 윈도우
- https://brunch.co.kr/@gnugeun/20

### 설치
- wget https://repo.anaconda.com/Miniconda3-latest-Linux-x86_64.sh
- chmod -x Miniconda3-latest_Linux-x86_64.sh
- ./Miniconda3-latest_Linux-x86_64.sh ( 쉘 스크립트 실행하여 설치한다. 엔터 혹은 yes만 입력 conda init 에서는 yes)
- sudo nano ~/.bashrc
- 맨 아랫 줄에 (export PATH=~/miniconda3(파일명)/bin:$PATH
- source ~/.bashrc 로 적용

### 비활성화하는방법
- conda config --set auto_activate_base false
- conda deactivate

### 활성화 하는 방법
- condat activate

### 가상환경 만들기
- conda create -n newenv(환경이름) python=3.8

### conda 가상환경 조회
- conda env list

### newenv 가상환경을 활성화
  - conda activate newenv
* 가상환경 지우는 방법
  - conda env remove -n newenv
* 설치 방법
  - conda install 패키지명
  - conda install -c conda-forge 패키지명 (저장소 지정하여 다운로드)
  - pip install 패키지명

## conda Vscode 확인
- Vscode 오른쪽 하단 (python 버전을 클릭)
- 상단 Select Interpreter 에 conda 가상환경을 확인후 선택 사용

# Tensorflow 설치
  - 설치할 환경을 활성화 (activate)

* keras 설치 (둘 중 택 1)
  - pip install keras
* tensorflow 설치 (cpu버전) (둘 중 택 1)
  - pip install tensorflow
  - conda install tensorflow
* Opencv 설치 (둘 중 택 1)
  - pip install opencv-contrib-python
  - conda install -c conda-forge opencv-contrib-python
* matplotlib 설치 (둘 중 택 1)
  - pip install matplotlib
  - conda install -c conda-forge matplotlib

# 티처블 머신 활용
* https://teachablemachine.withgoogle.com/ 에 접속해서 머신 생성
* 머신을 다운로드 받아서 활용

```python
from keras.models import load_model  # TensorFlow is required for Keras to work
import cv2  # Install opencv-python
import numpy as np

# Disable scientific notation for clarity
np.set_printoptions(suppress=True)

# Load the model
model = load_model("./src/conda/keras_model.h5", compile=False)

# Load the labels
class_names = open("./src/conda/labels.txt", "r").readlines()

# CAMERA can be 0 or 1 based on default camera of your computer
camera = cv2.VideoCapture(0)

while True:
    # Grab the webcamera's image.
    ret, image = camera.read()

    # Resize the raw image into (224-height,224-width) pixels
    image = cv2.resize(image, (224, 224), interpolation=cv2.INTER_AREA)

    # Show the image in a window
    cv2.imshow("Webcam Image", image)

    # Make the image a numpy array and reshape it to the models input shape.
    image = np.asarray(image, dtype=np.float32).reshape(1, 224, 224, 3)

    # Normalize the image array
    image = (image / 127.5) - 1

    # Predicts the model
    prediction = model.predict(image)
    index = np.argmax(prediction)
    class_name = class_names[index]
    confidence_score = prediction[0][index]

    # Print prediction and confidence score
    print("Class:", class_name[2:], end="")
    print("Confidence Score:", str(np.round(confidence_score * 100))[:-2], "%")

    # Listen to the keyboard for presses.
    keyboard_input = cv2.waitKey(1)

    # 27 is the ASCII for the esc key on your keyboard.
    if keyboard_input == 27:
        break

camera.release()
cv2.destroyAllWindows()

```

## ai_02_arduino.py
* pip install pysierial
* conda search로 설치가능한 파일 목록을 확인할 수 있다.
* conda install python=3.8.11 로 파이썬 버젼 변경 가능

```python
import serial
import tensorflow as tf
from keras.models import load_model
import cv2
import numpy as np
import time

def prepare():
    global model, className
    np.set_printoptions(suppress=True)

    model = load_model("./src/conda/keras_model.h5")
    className = open("./src/conda/labels.txt", "r").readlines()

def loop():
    
    cap = cv2.VideoCapture(0)
    
    while True:
        ret, image = cap.read()
        if not ret: 
            if cv2.waitKey(24) == 27: 
                continue
        
        # 티처블머신 스펙 (224x224) 이미지 크기를 설정
        image = cv2.resize(image, (224, 224), interpolation=cv2.INTER_AREA)
        cv2.imshow("Webcam Image", image)

        image = np.asarray(image, dtype=np.float32).reshape(1, 224, 224, 3)
        image = (image / 127.5) - 1

        prediction = model.predict(image)
        index = np.argmax(prediction) # 가장 높은 값의 인덱스를 반환
        classNames = className[index]
        confidenceScore = prediction[0][index]

        # [prediction]
        # [[0.4, 1.0, 0.8]]

        # print('confidenceScore: ', confidenceScore)

        # Print prediction and confidence score
        print("Class:", classNames[2:], end="")
        # '1.1122'[:-2] => 1.11
        print("Confidence Score:", str(np.round(confidenceScore * 100))[:-2], "%")
        # time.sleep(0.2)


        if confidenceScore >= 0.5:
            # TODO: 아두이노로 시리얼통신을 통해 명령 전달
            sendMsg(str(index+1))
        
        if cv2.waitKey(24) == 27:
            break

    pass

def sendMsg(msg):
    ser.write(msg.encode()) #.encode() -> bytes

PORT = '/dev/ttyUSB1'

if __name__ == '__main__':
    
    ser = serial.serial_for_url(PORT, baudrate=9600, timeout=1)

    prepare()
    loop()
```

#### 테스트 아두이노 코드

```c++
#define C 262
#define D 294
#define E 330
#define F 349
#define G 392
#define A 440
#define B 494
#define hC 523

int notes[] = {C, D, E, F, G, A, B, hC};

void setup() {
  Serial.begin(9600);
}

void loop() {
  if(Serial.available() > 0){
    char cmd = Serial.read();
    // 문자로 구성된 숫자를 정수형 숫자로 변형
    // ASCII 코드를 참조
    int index = (cmd - '0')-1;

    if(index > -1 && index < 8){
      int note = notes[index];
      tone(5, note, 200);
      delay(200);
    }
  }
}
```

## 이미지를 통한 해당되는 멜로디 출력

* 티처블 머신
    * 임의의 BGM 과 짝지어진 마스코트나 상징으로 사용될 목적으로 각 클래스를 구성하여 학습
    * 합습된 모델을 저장
* 아두이노
    * 임의의 BGM 3가지 준비 (슈퍼마리오, 아기상어, 엘리제를 위하여)
    * 각 BGM의 악보를 준비하고, 특정 명령에 따라 해당 BGM이 재생되도록 구성
    * 전달되는 명령은 시리얼 통신을 통해 전달됨
* 파이썬 프로그램
    * 티처블 머신으로 학습된 모델을 불러와 준비
    * 전체흐름
        * 사용자 에게 BGM과 관련된 지문을 주고 선택하도록 함
        * 해당 지문과 연결된 사진을 읽어오고 해당 사진을 학습된 모델로 분석
        * 분석된 결과로 구성된 명령을 아두이노로 시리얼 통신을 활용해 전달
        * 처음부터 반복
    * 콘솔은 텍스트로 지문을 구성하고(심볼의 이름)
        * Qt는 위젯을 통해 선택하도록함 ( 리스트에 사진이 보여야함 )
    * 프린트가 가능하다면 웹캠에 프린트된 사진을 비추어 지문을 선택하도록 하자!

```python

```









