# 일반 영상을 그림체로 변환

> 1. 영상의 크기를 구하기 w, h
> 2. 영상을 열고 캡쳐하기
> 3. 영상에 효과를 주기
> 4. 영상 닫기

* 영상의 회전 변환 - Rotation transformation
  * 회전 변환은 영상을 특정 각도만큼 회전 시키는 변환이다.
  * affine 행렬을 생성하고, affwrap 함수를 이용해서 간단히 회전 할 수 있다.
    * aff = np.array([[math.cos(rad), math.sin(rad), 0],   
                [-math.sin(rad), math.cos(rad), 0]], dtype=np.float32)   
      dst = cv2.warpAffine(src, aff, (0, 0))
  * 영상의 중앙 기준 회전 ( cv2.getRotationMatrix2D )
    * cv2.getRotationMatrix2D(center, angle, scale) -> retval
      * center : 회전 중심 좌표. (x, y) 튜플.
      * angle : (반시계 방향) 회전 각도 (degree). 음수는 시계 방향
      * scale : 추가적인 확대 비율
      * retval : 2x3 어파인 변환 행렬. 실수형
  * 회전 중심 좌표는 영상의 가로, 세로 1/2 값을 넣어주면 영상의 중앙 좌표로 설정할 수 있다.


```python
import cv2
import time
import random
import imageio

# first check
cap = cv2.VideoCapture('muyaho.mp4')

# muyaho video start
cap.set(1, 900)

w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))


fourcc = cv2.VideoWriter_fourcc('m','p','4','v')
out = cv2.VideoWriter('output_1.mp4', fourcc, cap.get(cv2.CAP_PROP_FPS)/2, (w,h))

# second check
while cap.isOpened():
    # false to ret is finished video
    ret, img = cap.read()
    if not ret:
        break
    
    # effective video
    if random.random() > 0.9:
        theta = random.randint(-3, 3)
        x, y = random.randint(-10, 10), random.randint(-10, 10)

        # imgs are rotated
        M = cv2.getRotationMatrix2D(center = (w//2, h//2), angle=theta, scale=1.0)
        M[0, 2] += x
        M[1, 2] += y

        # affine transformation
        img = cv2.warpAffine(img, M, (w, h))

    img = cv2.GaussianBlur(img, ksize=(9,9), sigmaX=0)

    # pencil sketch effect
    # sigma_s = 0~200, sigma_r = 0 to 1 default : 0.07
    # shade_factor = 0 to 0.1 default : 0.02
    res = cv2.resize(img, dsize=(w//2, h//2), interpolation=cv2.INTER_LINEAR)
    gray, color = cv2.pencilSketch(res, sigma_s =20, sigma_r = 0.03, shade_factor=0.02)

    cv2.imshow('gray', gray)
    out.write(cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR))

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break


out.release()
cap.release()
```

# Matrix Webcam
* K-Nearest Neighbor
* cv2.createBackgroundSubtractorKNN : 최근접 이웃 알고리즘
> * 비디오를 녹화하는 부분
> * K-nearest Neighbor 알고리즘을 사용해서 영상의 변화를 확인
> * 카메라 열어서 캡처
> * Morphological Transformations : 형태변환 (노이즈 제거, 표현 하고자 하는 사물의 선명화)

```python
import cv2

cap = cv2.VideoCapture(0)
bg_cap = cv2.VideoCapture('bg/bg3.mp4')

cap_size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))
fourcc = cv2.VideoWriter_fourcc('m','p','4','v')
out = cv2.VideoWriter('output.mp4', fourcc, cap.get(cv2.CAP_PROP_FPS), cap_size)

sub = cv2.createBackgroundSubtractorKNN(history=500, dist2Threshold=100, detectShadows=False)

while(cap.isOpened()):
    ret, frame = cap.read()
    if not ret: break

    bg_ret, bg_frame = bg_cap.read()
    # finished the video go to first frame
    if not bg_ret:
        bg_cap.set(1, 0)
        _, bg_frame = bg_cap.read()

    bg_frame = cv2.resize(bg_frame, dsize=cap_size)

    mask = sub.apply(frame)

    # 5*5 circular
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
    # morphology images noise erased from the background
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
    # morphology images noise erased from the background
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
    mask = cv2.dilate(mask, kernel, iterations=2)

    result = cv2.bitwise_and(bg_frame, frame, mask=mask)
    cv2.imshow('result', result)
    out.write(result)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

out.release()
cap.release()
bg_cap.release()

```

# Dib 설치하기
* 다운로드 참고 자료 : https://learnopencv.com/install-dlib-on-ubuntu/
> 1. 참고자료 : https://github.com/davisking/dlib/releases
> 2. Source code (tar.gz) 를 다운로드 받는다.
> 3. Downloads 경로로 이동
> 4. dlib-19.24.2.tar.gz 파일을 tar -xvf dlib-19.24.2.tar.gz로 압축을 풀어준다.
> 5. 다운로드 참고 자료 홈페이지의 Step 3.1에 있는 내용을 순서대로 진행해준다. cd ..까지 진행하면 된다.
> 6. Step 3.2의 sudo python3 setup.py install

# 포렌식 워터마킹
* 넷플릭스와 같은 비디오 서비스 업체들이 콘텐츠를 불법 유출로부터 보호하기 위해 사용하는 '멀티 DRM'기술이 있다.
* DRM 기술만으로는 콘텐츠를 불법 유출로부터 완벽하게 보호할 수 없다. 재생 과정에서 여러 가지 기술적인 한게로 인해 콘텐츠가 유출될 가능성이 있다.
> * 포렌식 워터마킹 ( Forensic Watermarking )은 디지털 워터마킹 이라는 기술의 한 분야이다.
>  > * 디지털 워터마킹은 사진이나 도영상과 같은 각종 디지털 데이터에 저작권 정보와 같은 비밀 정보를 삽입하여 관리하는 기술을 말한다.
>  > * 포렌식 워터마킹은 콘텐츠 사용자의 정보를 삽입해 불법 유포를 추적할 수 있도록 한다.
>  > * 콘텐으 저작권자, 서비스 제공자는 불법으로 유통되는 콘텐츠를 발견했을 떄 워터마크를 검출해 유출 경로와 사용자를 추적하고, 해당 사용자에게 서비스를 중지하거나 법적인 조치를 취하는 등의 방법으로 유출을 막을 수 있다.

### 포렌식 워터마킹 하기

```python
import cv2
import numpy as np
import random
import matplotlib.pyplot as plt

# 이미지 확인하기
img = cv2.imread('01.jpg')

# plt.figure(figsize=(16, 10))
plt.imshow(img[:, :, ::-1]) # 파일을 여는 부분
plt.show() # 파일을 여는 부분

# 워터마크로 사용할 이미지
img_wm = cv2.imread('icons-python.png')

# plt.imshow(img_wm[:, :, ::-1]) # 워터마크할 이미지
# plt.show() # 워터마크할 이미지

# 워터마크의 크기를 구하기 
height, width, _ = img.shape
wm_height, wm_width, _ = img_wm.shape

# 워터 마크의 크기는 이미지 보다 작아야됨!!
print(height, width)
print(wm_height, wm_width)

# Encode : 정보를 부호화/암호화 시키는 것

# Fast Fourier Transform 주파수 영역으로 변환 
# 변환하면 밝기 값만 나오게되는 데 주파수 영역에 워터마크를 심는다.
img_f = np.fft.fft2(img)

# 허수 영역
print(img_f[0, 0])

# 보안을 위해 암호화 작업
# 워터 마크를 랜덤으로 한 픽셀씩 흩뿌려서 입힌다. 
y_random_indices, x_random_indices = list(range(height)), list(range(width))
# 2021 값은 기억하고 있어야함. 
random.seed(2021)
random.shuffle(x_random_indices)
random.shuffle(y_random_indices)

# 0으로 초기화를 해주고 unsigned integer 8bit테이터 형태로 만들어주기 
random_wm = np.zeros(img.shape, dtype=np.uint8)

# 픽셀들을 하나씩 훑어가면서 랜덤한 위치에다가 워크마크를 흩어트린다. 
for y in range(wm_height):
    for x in range(wm_width):
        random_wm[y_random_indices[y], x_random_indices[x]] = img_wm[y, x]

# plt.figure(figsize=(16, 10)) # 워터마킹 이미지를 흩뿌린 결과 출력
# plt.imshow(random_wm) # 워터마킹 이미지를 흩뿌린 결과 출력
# # input이미지와 같은 크기
# plt.show() # 워터마킹 이미지를 흩뿌린 결과 출력

# input 이미지에 더해주기 
alpha = 5
# 랜덤한 워터마크에 알파값(5)
result_f = img_f + alpha * random_wm
# iff = invert fast fourier transform 으로 실수 영역으로 돌린다음에 
result = np.fft.ifft2(result_f)
# real : 실수로 변경해주는 코드 
result = np.real(result)
# 타입을 이미지 형태로 변경 
result = result.astype(np.uint8)

fig, axes = plt.subplots(1, 2, figsize=(20, 16))
# 원래 이미지 
axes[0].imshow(img[:, :, ::-1])
axes[0].set_title('Original')
axes[0].axis('off')
# forensic 이미지 
axes[1].imshow(result[:, :, ::-1])
axes[1].set_title('Forensic watermarked')
axes[1].axis('off')
fig.tight_layout()
# plt.show() # 워터마크가 된 이미지와 안된 이미지를 동시에 확인을 할 수 있다.

# plt.figure(figsize=(16, 10))
# # 사람 눈으로 구분이 안가기 때문에, result를 이미지에 빼기를 할 때 차이가 있음 
# plt.imshow(result - img)

# Decode 

# img_ori : 서버에 있는 원본이미지는 워터마크가 심어져 있지 않은 이미지 
# img_input : 불법 녹화 이미지는 워터마크가 심어져 있는 이미지 

# fft를 사용하여 주파수 영역으로 변경해준다. 
img_ori_f = np.fft.fft2(img)
img_input_f = np.fft.fft2(result)

# 원본 - 워터마크 포함된 이미지 = 워터마크 
watermark = (img_ori_f - img_input_f) / alpha
# 실수로 변경하고 다시 이미지화 
watermark = np.real(watermark).astype(np.uint8)

# plt.figure(figsize=(16, 10))
# plt.imshow(watermark)
# plt.show()

y_random_indices, x_random_indices = list(range(height)), list(range(width))
# 위에서 encode할 때와 똑같음. 
random.seed(2021)
random.shuffle(x_random_indices)
random.shuffle(y_random_indices)

result2 = np.zeros(watermark.shape, dtype=np.uint8)

for y in range(height):
    for x in range(width):
        result2[y, x] = watermark[y_random_indices[y], x_random_indices[x]]

# 결과값에서 워터마크가 나옴, 불법 복제되었다는 의미 
# plt.figure(figsize=(16, 10))
# plt.imshow(result2)
# plt.show()

# Result
fig, axes = plt.subplots(1, 3, figsize=(20, 16))
axes[0].imshow(img[:, :, ::-1])
axes[0].set_title('Original')
axes[0].axis('off')
axes[1].imshow(result[:, :, ::-1])
axes[1].set_title('Forensic watermarked')
axes[1].axis('off')
axes[2].imshow(result2)
axes[2].set_title('Watermark')
axes[2].axis('off')
fig.tight_layout()
# plt.show() # 모든 결과를 확인 할 수 있다.
```

# 동영상을 가지고 필터를 입힌것을 결과물로 만들기

```python
# 동영상을 가지고 필터를 입힌것을 결과물로 만들기
# 동영상을 가지고 필터를 입힌것을 결과물로 만들기
import cv2

cap = cv2.VideoCapture('fg/catmove2.mp4')
bg_cap = cv2.VideoCapture('bg/bg3.mp4')

cap_size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))
fourcc = cv2.VideoWriter_fourcc('m','p', '4', 'v')
out = cv2.VideoWriter('output.mp4', fourcc, cap.get(cv2.CAP_PROP_FPS), cap_size)

sub = cv2.createBackgroundSubtractorKNN(history=500, dist2Threshold=100, detectShadows=False)

while(cap.isOpened()):
    ret, frame = cap.read()
    if not ret:
        break
    bg_ret, bg_frame = bg_cap.read()
    if not bg_ret:
        bg_cap.set(1, 0)
        _, bg_frame = bg_cap.read()
    
    bg_frame = cv2.resize(bg_frame, dsize=cap_size)

    mask = sub.apply(frame)

    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
    mask = cv2.dilate(mask, kernel, iterations=2)
    result = cv2.bitwise_and(bg_frame, frame, mask=mask)
    gray, color = cv2.pencilSketch(frame, sigma_s = 90, sigma_r = 0.04, shade_factor=0.06)
    cv2.imshow('result', result)
    cv2.imshow('frame', frame)
    cv2.imshow('gray', gray)
    out.write(result)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

out.release()
cap.release()
bg_cap.release()
```





