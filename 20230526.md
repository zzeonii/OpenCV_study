# ROS를 활용한 하드웨어간 통신

## ROS 설치
- http://wiki.ros.org/ 로 접속
- ROS Noetic 버전으로 설치(install → ROS Noetic Ninjemys → Ubuntu)
- 터미널창 실행(1.2, 1.3, 1.4 맨윗줄, 1.4 Desktop-Full install을 순차적으로 입력하여 다운로드)
  - sudo sh -c 'echo "deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main"</br> > /etc/apt/sources.list.d/ros-latest.list'
  - sudo apt install curl # if you haven't already installed curl
  - curl -s https://raw.githubusercontent.com/ros/rosdistro/master/ros.asc | sudo apt-key add -
  - sudo apt update
  - sudo apt install ros-noetic-desktop-full  // 버전확인 잘하고 설치해야 한다
  - source /opt/ros/noetic/setup.bash   // 로스 사용할려면 꼭 해줘야한다
  - echo "source /opt/ros/noetic/setup.bash" >> ~/.bashrc   // 터미널 열 때마다 실행
  - sudo apt install python3-rosdep python3-rosinstall python3-rosinstall-generator </br>python3-wstool build-essential
  - sudo rosdep init
  - rosdep update

### 단축키 설정하기
- 터미널창에 gedit .bashrc 입력 후 119번째줄부터 124번째줄까지 아래 내용 입력
  - source ~/catkin_ws/devel/setup.bash
  - alias cw='cd ~/catkin_ws'
  - alias cs='cd ~/catkin_ws/src'
  - alias cm='cd ~/catkin_ws && catkin_make'
  - alias eb='gedit ~/.bashrc'
  - alias sb='source ~/.bashrc'
- 터미널창을 껐다켜주거나 source .bashrc명령어 입력을 해주면 단축키 설정한 것이 적용된다

### 기타 참고 사항
- 패키지 생성 : catkin_create_pkg 패키지이름
- mkdir -p catkin_ws/src : catkin_ws(부모폴더)안에 src폴더 생성
  - 터미널 창에 catkin_make를 입력하면 build, devel폴더가 생성된다
- 홈 디렉토리로 가는 방법 : cd, cd ~, cd /home/사용자 이름
- 터미널창 나누어서 사용 하기 : sudo apt install terminator

## 카메라 통신
> 1. catkin_create_pkg my_cam sensor_msgs cv_bridge rospy로 패키지 생성
>  - rosmsg show sensor_msgs/ (tap, tap)으로 내부 정보 확인
>  - rosmsg show sensor_msgs/Image로 이미지 메세지 정보 확인
>  - bridge가 ros와 opencv의 연결 역할
> 2. scripts 폴더 생성
> 3. my_cam_pub.py 파일 생성
```python
#!/usr/bin/ptyhon
# -*- coding: utf-8 -*-

import cv2
import rospy
from sensor_msgs.msg import Image
from cv_bridge import CvBridge, CvBridgeError

rospy.init_node("my_cam_pub ") # 노드 지정
cap = cv2.VideoCapture(0) # 카메라 연결

if cap.isOpened():
    pub = rospy.Publisher("my_image", Image, queue_size=10)
    bridge = CvBridge() # cv_bridge로 ros와 opencv의 데이터 변환에 사용

    fps = cap.get(cv2.CAP_PROP_FPS) 
    loop_rate = rospy.Rate(fps)

    while not rospy.is_shutdown():
        ret, frame = cap.read()
        if not ret:
            continue
        try:
            msg = bridge.cv2_to_imgmsg(frame, "bgr8") # frame을 img로 변환, brg8의 인코딩
            pub.publish(msg)
        except CvBridgeError as e:
            print(e) # 변환 에러에 대한 출력
        loop_rate.sleep()
```
> 4. my_cam_sub.py 파일 생성
```python
#!/usr/bin/ptyhon
# -*- coding: utf-8 -*-

import rospy
import cv2
from sensor_msgs.msg import Image
from cv_bridge import CvBridge, CvBridgeError

bridge = CvBridge()
def imgCallback(msg):
    try:
        frame = bridge.imgmsg_to_cv2(msg, "bgr8")
    except CvBridgeError as e:
        print(e)

    cv2.imshow("my_image", frame)
    cv2.waitKey(3)

rospy.init_node("my_cam_sub")
sub = rospy.Subscriber("my_image", Image, imgCallback, queue_size=10)
rospy.spin()
cv2.destroyAllWindows()
```
> 5. CMakeLists.txt의 Install 부분의 catkin_install_python을 추가
> 6. cm으로 빌드 후 roscore, rosrun my_cam my_cam_pub.py, rosrun my_cam my_cam_sub.py를 실행

![image](https://github.com/zzeonii/OpenCV_study/assets/129237950/894c1765-4197-45f7-a943-ca86c01599cc)

## 동일 네트워크 연결
#### ifconfig 명령어를 사용하려면 net-tools를 설치해야 한다
- sudo apt install net-tools
- ifconfig

![image](https://github.com/zzeonii/OpenCV_study/assets/129237950/09033f4d-517f-4619-9b49-794f284182df)

- eb로 bashrc 접속 후 맨 아래에 하기 문구 추가
  - export ROS_MASTER_URI=http://localhost:11311
  - export ROS_HOSTNAME=localhost
  - export ROS_MASTER_URI=http://192.168.0.44:11311
  - export ROS_HOSTNAME=192.168.0.50 # 본인 ip 주소
  - 띄어쓰기는 '_' 로 입력
- rostopic echo /hello
- rostopic pub /hello std_msgs/String 'dtal: hello'로 마스터에서 접속 host로 전송
#### 마스터에게 이미지 전송
- 구별을 위해서 노드 토픽의 이름을 수정
  - com50/my_image와 같이 namespace를 사용, 구분의 유용성을 높여준다
- 노드의 이름 수정, rospy.init_node('my_cam_pub', anonymous=True) 노드 이름 뒤에 랜덤한 숫자 생성
- 마스터는 rosnode list로 연결을 확인할 수 있다


# teachable Machine 활용
- classification
- 분류를 해주는 인공지능

> 1. https://teachablemachine.withgoogle.com 접속
> 2. 이미지 프로젝트로 생성
> epochs : 트레이닝의 양을 조절
> 3. previw 옆에 export model로 모델을 추출할 수 있다.
>       * Tensorflow.js : java를 사용할때 이용할 수 있다.
>       * Tensorflow.Lite : 안드로이드, TPU와 같은 소형화된 장비들에 사용된다.
>       * Tensorflow : 파이썬에 사용을 할때 쓴다.
> 4. Tensorflow -> download mymodel로 모델을 다운로드 해준다.
> 5. pip install tensorflow 로 텐서플로우를 다운로드 해준다.
> 6. 다운로드한 converted_keras.zip 압출을 풀어준다.
> 7. 압출 풀은 파일을 catkin_ws -> src -> my_cam에 model 폴더를 생성해서 옮겨준다.
>       * python3 -> import tensorflow를 사용하면 cudart_stub 학습용 프로그램의 유무를 확인할 수 있다.


## ROS에서 활용하기
- scripts 디렉토리에 my_model.py 생성
- Teachable Machine 다운로드에서 코드 복사
```python
#!/usr/bin/python
# -*- coding: utf-8 -*-

from keras.models import load_model  # TensorFlow is required for Keras to work
import cv2  # Install opencv-python
import numpy as np
import os 

# Disable scientific notation for clarity
np.set_printoptions(suppress=True)

file_path = os.path.abspath(__file__) # ~/catkin_ws/src/my_cam/scripts/my_model.py
dir_path = os.path.dirname(file_path) # ~/catkin_ws/src/my_cam/scripts/
model_path = os.path.join(dir_path, "..", "model", "keras_model.h5") # ~/catkin_ws/src/my_cam/model/keras_model.h5
label_path = os.path.join(dir_path, "..", "model", "labels.txt") # ~/catkin_ws/src/my_cam/model/labels.txt

# Load the model
# model = load_model("/home/a/catkin_ws/src/my_cam/model/keras_model.h5", compile=False)
model = load_model(model_path, compile=False)

# Load the labels
# class_names = open("/home/a/catkin_ws/src/my_cam/model/labels.txt", "r").readlines()
class_names = open(label_path, "r").readlines() 
# ["0 glasses", "1 lip glow", "2 pen"] 

# CAMERA can be 0 or 1 based on default camera of your computer
camera = cv2.VideoCapture(0)

while True:
    # Grab the webcamera's image.
    ret, image_og = camera.read()
    
    if not ret:
        continue

    # Resize the raw image into (224-height,224-width) pixels
    image = cv2.resize(image_og, (224, 224), interpolation=cv2.INTER_AREA)

    # Show the image in a window
    cv2.imshow("Webcam Image", image_og)

    # Make the image a numpy array and reshape it to the models input shape.
    image = np.asarray(image, dtype=np.float32).reshape(1, 224, 224, 3)

    # Normalize the image array
    image = (image / 127.5) - 1 # image / 255 * 2 - 1

    # Predicts the model
    prediction = model.predict(image)
    index = np.argmax(prediction)
    class_name = class_names[index]
    # ["0 glasses", "1 lip glow", "2 pen"][0] 
    confidence_score = prediction[0][index]

    # Print prediction and confidence score
    print("Class:", class_name[2:], end="")
    print("Confidence Score:", str(np.round(confidence_score * 100))[:-2], "%")

    # Listen to the keyboard for presses.
    keyboard_input = cv2.waitKey(1)

    # 27 is the ASCII for the esc key on your keyboard.
    if keyboard_input == 27:
        break

camera.release()
cv2.destroyAllWindows()
```
- import os : 운영체제와 관련된 정보를 가지고 있다
- set_printoptions : 과학적 표기를 없애준다
- join : 여러개의 값이 들어간다

![image](https://github.com/zzeonii/OpenCV_study/assets/129237950/d146ab03-0f66-4aed-87b6-5d4e91392ef5)


#### 클래스 이름, 확률을 화면에 웹캠화면에 띄우기 / 확률이 애매할 경우 ("I don't know.")문구 출력
```python
#!/usr/bin/python
# -*- coding: utf-8 -*-

from keras.models import load_model  # TensorFlow is required for Keras to work
import cv2  # Install opencv-python
import numpy as np
import os 

# Disable scientific notation for clarity
np.set_printoptions(suppress=True)

file_path = os.path.abspath(__file__) # ~/catkin_ws/src/my_cam/scripts/my_model.py
dir_path = os.path.dirname(file_path) # ~/catkin_ws/src/my_cam/scripts/
model_path = os.path.join(dir_path, "..", "model", "keras_model.h5") # ~/catkin_ws/src/my_cam/model/keras_model.h5
label_path = os.path.join(dir_path, "..", "model", "labels.txt") # ~/catkin_ws/src/my_cam/model/labels.txt

# Load the model
# model = load_model("/home/a/catkin_ws/src/my_cam/model/keras_model.h5", compile=False)
model = load_model(model_path, compile=False)

# Load the labels
# class_names = open("/home/a/catkin_ws/src/my_cam/model/labels.txt", "r").readlines()
class_names = open(label_path, "r").readlines() 
# ["0 glasses", "1 lip glow", "2 pen"] 

# CAMERA can be 0 or 1 based on default camera of your computer
camera = cv2.VideoCapture(0)

while True:
    # Grab the webcamera's image.
    ret, image_og = camera.read()
    
    if not ret:
        continue

    # Resize the raw image into (224-height,224-width) pixels
    image = cv2.resize(image_og, (224, 224), interpolation=cv2.INTER_AREA)



    # Make the image a numpy array and reshape it to the models input shape.
    image = np.asarray(image, dtype=np.float32).reshape(1, 224, 224, 3)

    # Normalize the image array
    image = (image / 127.5) - 1 # image / 255 * 2 - 1

    # Predicts the model
    prediction = model.predict(image)
    index = np.argmax(prediction)
    class_name = class_names[index]
    # ["0 glasses", "1 lip glow", "2 pen"][0] 
    confidence_score = prediction[0][index]
    
    if confidence_score < 0.8:
        text = "I don't know."

    # Print prediction and confidence score
    else:
        name = class_name[2:]
        result = str(np.round(confidence_score * 100))[:-2] + "%"
        text = name + " " + result
    print("Class:", name, end="")
    print("Confidence Score:",result)
    cv2.putText(image_og, text, (50,50), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 3)

    # Show the image in a window
    cv2.imshow("Webcam Image", image_og)

    # Listen to the keyboard for presses.
    keyboard_input = cv2.waitKey(1)

    # 27 is the ASCII for the esc key on your keyboard.
    if keyboard_input == 27:
        break

camera.release()
cv2.destroyAllWindows()

```
![image](https://github.com/zzeonii/OpenCV_study/assets/129237950/56003372-bacb-4896-9a3b-f8006afb3ef6)
![image](https://github.com/zzeonii/OpenCV_study/assets/129237950/2f82670f-e082-400a-9993-1e82c97d156c)


